# -*- coding: utf-8 -*-
"""Task4-ImagetoImage

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14HPa5ts0SAxa8LEoE1RF_dQqQLlwKd4P
"""

import os
from PIL import Image, ImageDraw, ImageFilter
import zipfile

# Step 1: Create directory
output_dir = "/content/sketch2real_building"
os.makedirs(output_dir, exist_ok=True)

# Step 2: Function to draw synthetic building + sketch
def create_building_pair(index):
    # Create base image
    real = Image.new("RGB", (256, 256), "skyblue")
    draw = ImageDraw.Draw(real)

    # Main building body
    draw.rectangle([60, 100, 196, 230], fill="lightgray", outline="black")

    # Windows
    for x in range(70, 190, 30):
        draw.rectangle([x, 120, x+15, 140], fill="yellow", outline="black")
        draw.rectangle([x, 160, x+15, 180], fill="yellow", outline="black")

    # Roof
    draw.rectangle([110, 60, 145, 100], fill="brown", outline="black")

    # Convert to sketch using edges
    sketch = real.convert("L").filter(ImageFilter.FIND_EDGES).convert("RGB")

    # Save images
    sketch.save(f"{output_dir}/input{index}.jpg")
    real.save(f"{output_dir}/target{index}.jpg")

# Step 3: Generate 5 image pairs
for i in range(1, 6):
    create_building_pair(i)

# Step 4: Zip the dataset
zip_path = "/content/sketch2real_building.zip"
with zipfile.ZipFile(zip_path, 'w') as zipf:
    for file in os.listdir(output_dir):
        filepath = os.path.join(output_dir, file)
        zipf.write(filepath, arcname=file)

print(f"‚úÖ Dataset zipped at:¬†{zip_path}")

from google.colab import files
files.download("/content/sketch2real_building.zip")

# Step 2: Extract zip
import zipfile
import os

with zipfile.ZipFile("sketch2real_building.zip", 'r') as zip_ref:
    zip_ref.extractall("/content/paired_data")

print("‚úÖ Files extracted to /content/paired_data")

!pip install -q git+https://github.com/tensorflow/examples.git
!pip install tensorflow matplotlib

# Step 4: Import libraries
import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
import glob
from tensorflow_examples.models.pix2pix import pix2pix
from IPython.display import clear_output

# Step 5: Preprocess images
def load_image_pair(input_path, target_path):
    input_image = tf.io.read_file(input_path)
    input_image = tf.image.decode_jpeg(input_image)
    input_image = tf.image.resize(input_image, [256, 256])
    input_image = (tf.cast(input_image, tf.float32) / 127.5) - 1

    target_image = tf.io.read_file(target_path)
    target_image = tf.image.decode_jpeg(target_image)
    target_image = tf.image.resize(target_image, [256, 256])
    target_image = (tf.cast(target_image, tf.float32) / 127.5) - 1

    return input_image, target_image

input_files = sorted(glob.glob("/content/paired_data/input*.jpg"))
target_files = sorted(glob.glob("/content/paired_data/target*.jpg"))

dataset = tf.data.Dataset.from_tensor_slices((input_files, target_files))
dataset = dataset.map(lambda x, y: load_image_pair(x, y))
dataset = dataset.shuffle(100).batch(1)

# Step 6: Build Generator & Discriminator
OUTPUT_CHANNELS = 3

generator = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')
discriminator = pix2pix.discriminator(norm_type='instancenorm', target=True)

loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)
LAMBDA = 100

def generator_loss(disc_generated_output, gen_output, target):
    gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)
    l1_loss = tf.reduce_mean(tf.abs(target - gen_output))
    return gan_loss + (LAMBDA * l1_loss)

def discriminator_loss(disc_real_output, disc_generated_output):
    real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)
    generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)
    return real_loss + generated_loss

# ‚úÖ No hidden characters here
generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)
discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)

# Step 7: Training step
@tf.function
def train_step(input_image, target):
    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
        gen_output = generator(input_image, training=True)

        disc_real_output = discriminator([input_image, target], training=True)
        disc_generated_output = discriminator([input_image, gen_output], training=True)

        gen_loss = generator_loss(disc_generated_output, gen_output, target)
        disc_loss = discriminator_loss(disc_real_output, disc_generated_output)

    generator_gradients = gen_tape.gradient(gen_loss, generator.trainable_variables)
    discriminator_gradients = disc_tape.gradient(disc_loss, discriminator.trainable_variables)

    generator_optimizer.apply_gradients(zip(generator_gradients, generator.trainable_variables))
    discriminator_optimizer.apply_gradients(zip(discriminator_gradients, discriminator.trainable_variables))

    return gen_loss, disc_loss  # ‚úÖ Cleaned space here

# Step 8: Training loop
EPOCHS = 15

for epoch in range(EPOCHS):
    print(f"\nüîÅ Epoch {epoch+1}/{EPOCHS}")
    for step, (input_image, target) in dataset.enumerate():
        gen_loss, disc_loss = train_step(input_image, target)
        if step % 10 == 0:
            print(f"Step {step.numpy()}: Gen Loss = {gen_loss:.4f}, Disc Loss = {disc_loss:.4f}")

import matplotlib.pyplot as plt

# Updated function to generate prediction and display with ground truth
def generate_images(model, input_image, target_image=None):
    prediction = model(input_image, training=False)
    plt.figure(figsize=(18, 5))

    display_list = [input_image[0], prediction[0]]
    title = ['Input (Sketch)', 'Prediction (Generated Real)']

    if target_image is not None:
        display_list.append(target_image[0])
        title.append('Target (Actual Real)')

    for i in range(len(display_list)):
        plt.subplot(1, len(display_list), i + 1)
        plt.title(title[i])
        plt.imshow((display_list[i].numpy() + 1) / 2.0)
        plt.axis('off')

    plt.tight_layout()
    plt.show()

# Generate output from updated dataset
for example_input, example_target in dataset.take(1):
    generate_images(generator, example_input, example_target)  # ‚úÖ fixed

from google.colab import files
uploaded = files.upload()

from PIL import Image
import numpy as np
import tensorflow as tf

def load_and_preprocess_image(image_path):
    img = Image.open(image_path).convert('RGB')
    img = img.resize((256, 256))
    img = np.array(img).astype(np.float32)
    img = (img / 127.5) - 1
    img = np.expand_dims(img, axis=0)
    return tf.convert_to_tensor(img)

custom_image = load_and_preprocess_image('Screenshot 2025-07-03 185731.png')  # Replace with your filename
generate_images(generator, custom_image)